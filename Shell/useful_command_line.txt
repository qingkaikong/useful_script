#In this file, I will keep a record of some of the useful command line
#Note all these commands are tested under bash. 

#1 show the calendar
cal 2 1015

#1a show julian day
cal -jy

#2 list long format files sorted by reverse time order with human readable format
ls -ltrh

#3 redirect and append to file of the output of a program
ls -l /usr/bin > ls-output.txt
ls -l /usr/bin >> ls-output.txt

#4 bash references standard input, output, and error as file descriptors 0, 1, and 2
#so if I want to log the standard error into a file
ls -l /bin/usr 2> ls-error.txt

#5 if we want to redirect output and error into one file there are two ways
#a) two redirections, the second is redirect file descriptor 2 to file descriptor 1
ls -l /bin/usr > ls-output.txt 2>&1
#b) ls -l /bin/usr &> ls-output.txt

#6 Disposing unwanted output (just ignore)
ls -l /bin/usr 2> /dev/null

#7 use cat to create a new file
cat lazy_dag.txt

#8 pipeline
ls -l /usr/bin | less

#9 filters take input, change it somehow, and then output it
ls /bin /usr/bin | sort | less

#10 uniq accepts a sorted list of data from either standard input or a single 
#filename argument and removes any duplicates from the list. 
ls /bin /usr/bin | sort | uniq | less

#10b if we want to see the duplicates instead, we add -d option 
ls /bin /usr/bin | sort | uniq -d | less

#11 count the number of lines, words, and bytes
ls /bin /usr/bin | sort | uniq | wc -l 

#12 find files contain zip in the name, use -i option to ignore case, and -v only
#show the lines not match the pattern
ls /bin /usr/bin | sort | uniq | grep zip

#13 Monitoring log files in real time
tail -f /var/log/messages

#14 Using 'T' fitting on pipe, this will both output to the file and standard output
ls /usr/bin | tee ls.txt | grep zip

#15 Display two files side by side, -m merge the files, and -t to omit headers
# -w $Column to specify how many columns to display 
pr -m -t -w 100 one.txt two.txt

#16 Arithmetic expansion
echo $(($((5**2)) * 3))

#17 Brace Expansion
echo Front-{A,B,C}-Back
echo Number_{1..5}
echo {Z..A}
mkdir {2009..2011}-0{1..9} {2009..2011}-{10..12}

#18 command expansion
echo $(ls)

#19 Quoting, the effect of single quoting (suppress all expansions), double quoting
echo text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER
echo "text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER"

#20 if I have many files with the name A_20140101_B_C.data, I want to get the part which
#contains number (20140101), and count the number of files that contain unique number
ls *.data | awk -F "_" '{print $2}' | sort | uniq | wc

#21 Check the history and use some of the previous commands
history
!22      #use the number 22 command
#more history expansion commands
!! Repeat the last command.
!number Repeat history list item number
!string Repeat last history list item starting with string
!?string Repeat last history list item containing string

#23 Viewing Processes
ps
ps x
ps aux

#24 Dynamic view of processes
top

#25 Put program in background
xlogo &
#put the program back to forefront 
jobs
fg %1

#26 kill a process
kill PID
killall name

#27 Show the environment variable
printenv
printenv USER

#28 set without argument will print out all the environment and shell variables
set | less
#same as alias
alias

#29 Check the size of the folder
du -hsc *
#showing the disk space
df

#30 history
history
!!
#run the 20th command
!20

#31 irobot, this is mac fun
say how are you
#read a file
say -f /path/to/file.txt

#32 create file for any size
mkfile 1g test.abc

#33 get my ip address
ipconfig getifaddr en1
#get my public ip address
curl ipecho.net/plain ; echo

#34 list of commands
http://ss64.com/osx/

#35 search using spotlight
mdfind -onlyin ~/Documents essay 

#36 copy and past to 
ls ~ | pbcopy 
pbcopy < blogpost.txt 
pbpaste >> tasklist.txt 

#37 Watch star wall in ASCII
telnet towel.blinkenlights.nl

#38 unzip the files to the directory
ls *.zip|awk -F'.zip' '{print "unzip "$0" -d "$1}'|sh

#39 Command w, combine of uptime and who
w

#40 if a data file is separated by '|', we just want to get the sum of the 
#4th column
cat data.csv | awk -F "|" '{ sum += $4 } END { printf "%.2f\n", sum }'

#41 show the first 3 or the last 3 lines
head -n 3 data.csv
tail -n 3 data.csv

#42 wc will quickly tell you how many lines, words, and bytes are in a file
wc data.csv

######################Some commands for viewing large data files######################
#43 grep -i (ignore case), -r (recursively search directories), -B N (N lines before), -A N (N lines after).
grep -i -B 1 -A 1 steal data.csv
# 17:25||2-4|Darius Theus Turnover.
# 17:25|Terrell Vinson Steal.|2-4|
# 17:18|Chaz Williams made Layup.  Assisted by Terrell Vinson.|4-4|

#44 sed
grep Block data.csv | head -n 3
# 16:43||5-4|Juvonte Reddic Block.
# 15:37||7-6|Troy Daniels Block.
# 14:05|Raphiael Putney Block.|11-8|

sed -e 's/Block/Rejection/g' data.csv > rejection.csv
# replace all instances of the word 'Block' in data.csv with 'Rejection'
# stream the results to a new file called rejection.csv

grep Rejection rejection.csv | head -n 3
# 16:43||5-4|Juvonte Reddic Rejection.
# 15:37||7-6|Troy Daniels Rejection.
# 14:05|Raphiael Putney Rejection.|11-8|

#45 sort
head -n 5 data.csv
# time|away|score|home
# 20:00||0-0|Jump Ball won by Virginia Commonwealt.
# 19:45||0-0|Juvonte Reddic Turnover.
# 19:45|Chaz Williams Steal.|0-0|
# 19:39|Sampson Carter missed Layup.|0-0|

head -n 5 data.csv | sort
# 19:39|Sampson Carter missed Layup.|0-0|
# 19:45|Chaz Williams Steal.|0-0|
# 19:45||0-0|Juvonte Reddic Turnover.
# 20:00||0-0|Jump Ball won by Virginia Commonwealt.
# time|away|score|home

# columns separated by '|', sort on column 2 (-k2), case insensitive (-f)
head -n 5 data.csv | sort -f -t'|' -k2
# time|away|score|home
# 19:45|Chaz Williams Steal.|0-0|
# 19:39|Sampson Carter missed Layup.|0-0|
# 20:00||0-0|Jump Ball won by Virginia Commonwealt.
# 19:45||0-0|Juvonte Reddic Turnover.

#46 Sometimes you want to check for duplicate records in a large text file 
#- that's when uniq comes in handy. By using the -c parameter, uniq will output 
#the count of occurrences along with the line. You can also use the -d and -u 
#parameters to output only duplicated or unique records.
sort data.csv | uniq -c | sort -nr | head -n 7
#   2 8:47|Maxie Esho missed Layup.|46-54|
#   2 8:47|Maxie Esho Offensive Rebound.|46-54|
#   2 7:38|Trey Davis missed Free Throw.|51-56|
#   2 12:12||16-11|Rob Brandenberg missed Free Throw.
#   1 time|away|score|home
#   1 9:51||20-11|Juvonte Reddic Steal.

sort data.csv | uniq -d
# 12:12||16-11|Rob Brandenberg missed Free Throw.
# 7:38|Trey Davis missed Free Throw.|51-56|
# 8:47|Maxie Esho Offensive Rebound.|46-54|
# 8:47|Maxie Esho missed Layup.|46-54|

sort data.csv | uniq -u | wc -l
#     369 (unique lines)

#47 convert all html files to txt
textutil -convert txt `ls *.html`

#48 rename all the XXX.BN2.sac to XXX.BNZ.sac
rename 's/BN2/BNZ/' *.BN2*

#49 in Vi
#search and replace
:%s/Line/line/g

# the following few commands related with hardware checking on linux
#50 Find number of CPU
lscpu

#51 Find CPU information
cat /proc/cpuinfo

#52 Find Memory information
cat /proc/meminfo
free -mh

#53 Find current running kernel version
cat /proc/version
uname -a
unam -mrs
(https://www.cyberciti.biz/faq/linux-command-to-find-the-system-configuration-and-hardware-information/)

#54 Find GPU information
cat /proc/driver/nvidia/gpus/0/information
lspci -vnn | grep VGA -A 12

Script 
#1 script to check if the input year is leap year
clear
echo "enter year"
read y
k='expr $y%4'
if test $k -eq 0 
then
echo "leap year"
else
echo "not a leap year"
fi

#2 find out the greatest among three inputs
clear
echo "enter the value of a b c"
read a
read b
read c
if test $a -gt $b -a $a -gt $c 
then
echo "a is greatest"
else 
if test $b -gt $c 
then
echo "b is greatest"
else
echo "c is greatest"
fi
fi

#3 remove files in one folder that are exist in another folder
for file in *
do
   rm /other-directory/"$file"
done













































